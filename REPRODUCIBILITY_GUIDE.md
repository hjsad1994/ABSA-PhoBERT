# Reproducibility Guide for Research

## ğŸ¯ Má»¥c ÄÃ­ch

Äáº£m báº£o káº¿t quáº£ nghiÃªn cá»©u cÃ³ thá»ƒ **tÃ¡i táº¡o (reproducible)** vá»›i cÃ¹ng káº¿t quáº£ khi cháº¡y láº¡i vá»›i cÃ¹ng seed.

## ğŸ”§ Configuration

### Seed Configuration trong `config.yaml`

```yaml
reproducibility:
  # Master seed - applied to all random operations
  seed: 42
  
  # Data preprocessing
  data_split_seed: 42        # Seed for train/val/test split
  oversampling_seed: 42      # Seed for per-aspect oversampling
  shuffle_seed: 42           # Seed for data shuffling
  
  # Training
  training_seed: 42          # Seed for model training
  data_loader_seed: 42       # Seed for data loader workers
```

**Quan trá»ng:** Táº¥t cáº£ seeds pháº£i giá»‘ng nhau (42) Ä‘á»ƒ Ä‘áº£m báº£o reproducibility!

## ğŸ“Š Workflow

### 1. Data Preprocessing (vá»›i seed)

```bash
# Sá»­ dá»¥ng seed tá»« config
python preprocess_data.py

# Hoáº·c override seed tá»« command line
python preprocess_data.py --seed 42
```

**Output:**
- `data/train.csv` (12,455 samples)
- `data/val.csv` (1,556 samples)
- `data/test.csv` (1,558 samples)

**Reproducible:** Cháº¡y láº¡i vá»›i cÃ¹ng seed sáº½ cho cÃ¹ng train/val/test split!

### 2. Oversampling (vá»›i seed)

```bash
# Sá»­ dá»¥ng seed tá»« config
python oversample_train.py

# Hoáº·c override seed tá»« command line
python oversample_train.py --seed 42
```

**Output:**
- `data/train_oversampled.csv` (21,060 samples)

**Reproducible:** Cháº¡y láº¡i vá»›i cÃ¹ng seed sáº½ cho cÃ¹ng oversampled data!

### 3. Training (vá»›i seed)

```bash
# Seed Ä‘Æ°á»£c Ä‘á»c tá»« config tá»± Ä‘á»™ng
python train_phobert_trainer.py
```

**Seed Ä‘Æ°á»£c sá»­ dá»¥ng:**
- Model initialization
- Weight initialization
- Dropout
- Data shuffling trong DataLoader
- Optimizer state

**Reproducible:** Cháº¡y láº¡i vá»›i cÃ¹ng seed sáº½ cho cÃ¹ng training trajectory!

## âœ… Verification

### Kiá»ƒm tra cáº¥u hÃ¬nh:

```bash
python verify_reproducibility.py
```

**Script nÃ y sáº½ check:**
1. âœ“ All seeds trong config cÃ³ giá»‘ng nhau khÃ´ng
2. âœ“ Data split cÃ³ reproducible khÃ´ng
3. âœ“ Oversampling cÃ³ reproducible khÃ´ng
4. âœ“ Files Ä‘Ã£ tá»“n táº¡i chÆ°a

**Output máº«u:**

```
================================================================================
REPRODUCIBILITY VERIFICATION FOR RESEARCH
================================================================================

================================================================================
SEED CONFIGURATION CHECK
================================================================================

Master Seed: 42

Seed Configuration:
  âœ“ Data Split         : 42
  âœ“ Oversampling       : 42
  âœ“ Shuffle            : 42
  âœ“ Training           : 42
  âœ“ Data Loader        : 42

âœ… All seeds are consistent!
   All random operations use seed: 42

================================================================================
DATA SPLIT REPRODUCIBILITY TEST
================================================================================

Testing with seed: 42

âœ… Data split is reproducible!
   Same seed produces identical train/val/test splits

================================================================================
OVERSAMPLING REPRODUCIBILITY TEST
================================================================================

Testing with seed: 42

âœ… Oversampling is reproducible!
   Same seed produces identical oversampled datasets

================================================================================
SUMMARY
================================================================================

âœ… ALL CHECKS PASSED!

Your configuration ensures reproducible results:
  â€¢ All seeds are consistent (seed=42)
  â€¢ Data splitting is reproducible
  â€¢ Oversampling is reproducible
```

## ğŸ”¬ Multiple Experiments (Different Seeds)

Äá»ƒ nghiÃªn cá»©u robust, cháº¡y experiments vá»›i nhiá»u seeds khÃ¡c nhau:

### Experiment 1: Seed 42
```bash
# Update config.yaml: seed: 42
python preprocess_data.py --seed 42
python oversample_train.py --seed 42
python train_phobert_trainer.py
# Rename output: mv checkpoints/phobert_finetuned checkpoints/phobert_seed42
```

### Experiment 2: Seed 123
```bash
# Update config.yaml: seed: 123
python preprocess_data.py --seed 123
python oversample_train.py --seed 123
python train_phobert_trainer.py
# Rename output: mv checkpoints/phobert_finetuned checkpoints/phobert_seed123
```

### Experiment 3: Seed 456
```bash
# Update config.yaml: seed: 456
python preprocess_data.py --seed 456
python oversample_train.py --seed 456
python train_phobert_trainer.py
# Rename output: mv checkpoints/phobert_finetuned checkpoints/phobert_seed456
```

### So sÃ¡nh káº¿t quáº£:

```python
import pandas as pd
import matplotlib.pyplot as plt

results = {
    'seed_42': {
        'f1': 0.9234,
        'accuracy': 0.9312
    },
    'seed_123': {
        'f1': 0.9198,
        'accuracy': 0.9287
    },
    'seed_456': {
        'f1': 0.9256,
        'accuracy': 0.9328
    }
}

# Report mean Â± std
f1_scores = [r['f1'] for r in results.values()]
print(f"F1: {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}")
# Example: F1: 0.9229 Â± 0.0024
```

## ğŸ“ Best Practices for Research

### 1. âœ… Document Your Seeds
```yaml
# config.yaml
reproducibility:
  seed: 42  # Main experiment
  # Alternative seeds for robustness: 123, 456, 789, 2024
```

### 2. âœ… Version Control Your Data Splits
```bash
# After running preprocess_data.py with seed 42
git add data/train.csv data/val.csv data/test.csv
git commit -m "Data split with seed 42"
```

### 3. âœ… Save Seed Info with Results
```python
# In your paper/report
"""
Results (seed=42):
  F1 Score: 0.9234
  Accuracy: 0.9312
  
Results averaged over 3 seeds (42, 123, 456):
  F1 Score: 0.9229 Â± 0.0024
  Accuracy: 0.9309 Â± 0.0017
"""
```

### 4. âœ… Log Seeds in Training Logs
```
Training log sáº½ tá»± Ä‘á»™ng ghi:
  Random seed for training: 42
  (Ensures reproducible results for research)
```

## ğŸš« Common Mistakes

### âŒ Mistake 1: Hardcoded Seeds
```python
# BAD - hardcoded
df.sample(frac=1, random_state=42)

# GOOD - tá»« config
seed = config['reproducibility']['seed']
df.sample(frac=1, random_state=seed)
```

### âŒ Mistake 2: Inconsistent Seeds
```yaml
# BAD
reproducibility:
  data_split_seed: 42
  training_seed: 123  # Different!

# GOOD
reproducibility:
  data_split_seed: 42
  training_seed: 42   # Same!
```

### âŒ Mistake 3: KhÃ´ng kiá»ƒm tra Reproducibility
```bash
# ALWAYS verify before experiments
python verify_reproducibility.py
```

## ğŸ“š Files Modified for Reproducibility

1. **config.yaml**
   - Added `reproducibility` section with all seeds

2. **preprocess_data.py**
   - Reads `data_split_seed` from config
   - Accepts `--seed` argument to override
   - Logs seed being used

3. **oversample_train.py**
   - Reads `oversampling_seed` from config
   - Accepts `--seed` argument to override
   - Logs seed being used

4. **train_phobert_trainer.py**
   - Reads `training_seed` from config
   - Priority: `reproducibility.training_seed` > `training.seed` > `general.seed`
   - Logs seed being used

5. **verify_reproducibility.py** (NEW)
   - Verification script
   - Tests data split reproducibility
   - Tests oversampling reproducibility

## âœ… Checklist

TrÆ°á»›c khi cháº¡y experiments:

- [ ] ÄÃ£ cáº­p nháº­t `config.yaml` vá»›i seeds nháº¥t quÃ¡n
- [ ] ÄÃ£ cháº¡y `python verify_reproducibility.py` vÃ  pass táº¥t cáº£ checks
- [ ] ÄÃ£ document seed Ä‘ang sá»­ dá»¥ng
- [ ] ÄÃ£ version control data splits (náº¿u dÃ¹ng git)
- [ ] ÄÃ£ backup káº¿t quáº£ vá»›i seed info

## ğŸ“ For Academic Papers

### Reporting Reproducibility:

```latex
\section{Experimental Setup}

All experiments were conducted with fixed random seeds to ensure 
reproducibility. We used seed 42 for data splitting (80/10/10 
train/validation/test), per-aspect oversampling, and model training. 
To evaluate robustness, we also ran experiments with seeds 123, 456, 
789, and 2024. Results are reported as mean Â± standard deviation 
across all five seeds.

\subsection{Reproducibility}

Our code and configuration are available at [repository link]. 
To reproduce our results:

1. Install dependencies: \texttt{pip install -r requirements.txt}
2. Preprocess data: \texttt{python preprocess\_data.py --seed 42}
3. Oversample training data: \texttt{python oversample\_train.py --seed 42}
4. Train model: \texttt{python train\_phobert\_trainer.py}

All random operations use the same seed (42) for full reproducibility.
```

---

**âœ… Reproducibility Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº£m báº£o! Sáºµn sÃ ng cho nghiÃªn cá»©u!**
